{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbaaf8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from scipy.spatial.transform import Rotation as rotation\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "#https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ecdc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cv_image(image):\n",
    "    image = (image.transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "def to_cv_kp(kp):\n",
    "    return list(map(lambda x: cv.KeyPoint(x[1], x[0], 0), kp))\n",
    "\n",
    "def draw_cv_kp(image, kp, color=(0, 255, 0)):\n",
    "    return cv.drawKeypoints(image, kp, None, color=color)\n",
    "\n",
    "\n",
    "def to_cv_dmatch(match_indices):\n",
    "    return list(map(lambda x: cv.DMatch(x[0], x[1], 0, 0), zip(np.arange(0, len(match_indices)), match_indices)))\n",
    "\n",
    "\n",
    "def draw_cv_matches(image1, image2,\n",
    "                    kp1, kp2,\n",
    "                    match_indices,\n",
    "                    match_mask=None, match_color=(0, 255, 0), single_point_color=(255, 0, 0)):\n",
    "    cv_match_indices = to_cv_dmatch(match_indices)\n",
    "    \n",
    "    if match_mask is not None:\n",
    "        flags = cv.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS\n",
    "        \n",
    "        match_mask = match_mask.tolist()\n",
    "        \n",
    "    else:\n",
    "        flags = None\n",
    "    \n",
    "    return cv.drawMatches(image1, kp1, image2, kp2, cv_match_indices, None, \n",
    "                          matchColor=match_color, \n",
    "                          singlePointColor=single_point_color,\n",
    "                          matchesMask=match_mask,\n",
    "                         flags=flags)\n",
    "\n",
    "\n",
    "def plot_figures(figures, nrows=1, ncols=1, size=(18, 18)):\n",
    "    \"\"\"Plot a dictionary of figures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    figures : <title, figure> dictionary\n",
    "    ncols : number of columns of subplots wanted in the display\n",
    "    nrows : number of rows of subplots wanted in the figure\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes_list = plt.subplots(ncols=ncols, nrows=nrows, figsize=size)\n",
    "    for ind, title in zip(range(len(figures)), figures):\n",
    "        if nrows * ncols != 1:\n",
    "            axes_list.ravel()[ind].imshow(figures[title], cmap='gray')\n",
    "            axes_list.ravel()[ind].set_title(title)\n",
    "            axes_list.ravel()[ind].set_axis_off()\n",
    "        else:\n",
    "            axes_list.imshow(figures[title], cmap='gray')\n",
    "            axes_list.set_title(title)\n",
    "            axes_list.set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01623fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(img):\n",
    "    return cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "def bgr2rgb(img):\n",
    "    return cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "def GaussianFilter(img, gausFil):\n",
    "    return cv.GaussianBlur(imgGray, gausFil, 1)\n",
    "\n",
    "def darw(img1, img2, title = \"Results\"):\n",
    "    cv.imshow(title, np.hstack([img1, img2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07a53739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyPoints(img, type):\n",
    "    tmp = img.copy()\n",
    "    imgGray = rgb2gray(bgr2rgb(tmp))\n",
    "\n",
    "    if type == \"SIFT\":\n",
    "        sift = cv.SIFT_create(nfeatures=8000)\n",
    "        kp = sift.detect(imgGray,None)\n",
    "        kp, des = sift.detectAndCompute(imgGray,None)\n",
    "        imgRes = cv.drawKeypoints(imgGray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    elif type == \"ORB\":\n",
    "        orb = cv.ORB_create()\n",
    "        kp, des = orb.detectAndCompute(imgGray,None)\n",
    "        imgRes = cv.drawKeypoints(imgGray,kp,tmp,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    return np.array(kp), np.array(des), imgRes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17d02c",
   "metadata": {},
   "source": [
    "# nnMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcadfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnMatching(image1, image2,kp1, kp2, kp1_desc, kp2_desc, num = -1):\n",
    "    #m = min(len(kp1_desc),len(kp2_desc))\n",
    "    #R = np.arange(m)\n",
    "    #dist = np.linalg.norm(kp1_desc[R[0:],None,:] - kp2_desc[None,R[0:],:], axis = -1)\n",
    "    \n",
    "    dist = np.linalg.norm(kp1_desc[:,None,:] - kp2_desc[None,:,:], axis = -1)\n",
    "\n",
    "    nn_idx1 = dist.argmin(axis = 1)\n",
    "\n",
    "    Res = plot_figures({'nn matching': draw_cv_matches(image1, image2, \n",
    "                                                      kp1, kp2, \n",
    "                                                      nn_idx1[0:num])})\n",
    "    return Res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6cb7d",
   "metadata": {},
   "source": [
    "# Low Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f71adb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowRatio(image1, image2, kp1, kp1_desc, kp2, kp2_desc, r = 0.95, num = -1):\n",
    "    #m = min(len(kp1_desc),len(kp2_desc))\n",
    "    #R = np.arange(m)\n",
    "    #dist = np.linalg.norm(kp1_desc[R,None,:] - kp2_desc[None,R,:], axis = -1)\n",
    "\n",
    "    dist = np.linalg.norm(kp1_desc[:,None,:] - kp2_desc[None,:,:], axis = -1)\n",
    "    \n",
    "    nn_idx1 = dist.argmin(axis = -1)\n",
    "    \n",
    "    nn_dist1 = np.sort(dist, axis=-1)\n",
    "    ratio1 = nn_dist1[:,0]/nn_dist1[:,1]\n",
    "    ratio_test_mask1 = ratio1 < r \n",
    "\n",
    "    Res = plot_figures({'Low Rartio': draw_cv_matches(image1, image2,\n",
    "                                                                       kp1, kp2,\n",
    "                                                                       nn_idx1[0:num],\n",
    "                                                                       ratio_test_mask1.astype(int)[0:num])})\n",
    "    return Res\n",
    "\n",
    "\n",
    "def mutual_lowRatio(image1, image2, kp1, kp1_desc, kp2, kp2_desc, r = 0.95, num = -1):\n",
    "    #m = min(len(kp1_desc),len(kp2_desc))\n",
    "    #R = np.arange(m)\n",
    "    #dist = np.linalg.norm(kp1_desc[R,None,:] - kp2_desc[None,R,:], axis = -1)\n",
    "\n",
    "    dist = np.linalg.norm(kp1_desc[:,None,:] - kp2_desc[None,:,:], axis = -1)\n",
    "#     print(dist.shape)\n",
    "    nn_idx1 = dist.argmin(axis = -1)\n",
    "    \n",
    "    nn_dist1 = np.sort(dist, axis=-1)\n",
    "    ratio1 = nn_dist1[:,0]/nn_dist1[:,1]\n",
    "    ratio_test_mask1 = ratio1 < r \n",
    "    \n",
    "    nn_idx2 = np.argmin(dist,axis=0)\n",
    "    nn_dist2=np.sort(dist,axis=0)\n",
    "    ratio_test_mask2 = (nn_dist2[0,:]/nn_dist2[1,:]<r)\n",
    "    \n",
    "    numbers=np.arange(kp1_desc.shape[0])\n",
    "    mutual_mask = (nn_idx2[nn_idx1[:]]==numbers[:])\n",
    "\n",
    "    ratio_test_combine=ratio_test_mask1*ratio_test_mask2[nn_idx1]\n",
    "    match_mask = ratio_test_combine*mutual_mask\n",
    "    \n",
    "    kp_ind_filtered=np.zeros((1,2))\n",
    "    for i in range(len(kp1)):\n",
    "        if match_mask[i]:\n",
    "            kp_ind_filtered=np.vstack((kp_ind_filtered,np.array([i,nn_idx1[i]])[None]))\n",
    "    kp_ind_filtered=kp_ind_filtered[1:].astype(int)\n",
    "    Res = plot_figures({'Low Rartio': draw_cv_matches(image1, image2,\n",
    "                                                       kp1, kp2,\n",
    "                                                       nn_idx1[0:num],\n",
    "                                                       match_mask.astype(int)[0:num])})\n",
    "    return Res,kp_ind_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72846f",
   "metadata": {},
   "source": [
    "# Brute-Force Matching with ORB Descriptors\n",
    "https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70ea166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFMatching(image1, image2, kp1, kp2, kp1_desc, kp2_desc, num = -1):\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)# create BFMatcher object\n",
    "    matches = bf.match(kp1_desc,kp2_desc)# Match descriptors.\n",
    "    matches = sorted(matches, key = lambda x:x.distance)# Sort them in the order of their distance.\n",
    "\n",
    "    Res = cv.drawMatches(image1,kp1,image2,kp2,matches[:num],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)# Draw first 10 matches.\n",
    "    Res = plot_figures({'BFMatching(NORM_HAMMING)':Res})\n",
    "    return Res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69f4e1",
   "metadata": {},
   "source": [
    "# Brute-Force Matching with SIFT Descriptors and Ratio Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fe5293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFMatSiftLowR(image1, image2, k = 2, r = 0.95,  num = 10):\n",
    "    kp1, kp1_desc, imgRes1 = keyPoints(image1.copy(), type=\"SIFT\")\n",
    "    kp2, kp2_desc, imgRes2 = keyPoints(image2.copy(), type=\"SIFT\")\n",
    "\n",
    "    # BFMatcher with default params\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(kp1_desc,kp2_desc,k)\n",
    "    # Apply ratio test\n",
    "    \n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append([m])\n",
    "    Res = cv.drawMatchesKnn(image1,kp1[:num],image2,kp2[:num],good[:num],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    Res = plot_figures({'Brute-Force Matching with SIFT Descriptors and Ratio Test':Res})\n",
    "    return Res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843614b",
   "metadata": {},
   "source": [
    "# adalam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe3e88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#python -m pip install http://download.pytorch.org/whl/cu80/torch-0.2.0.post3-cp35-cp35m-manylinux1_x86_64.whl \n",
    "#python -m pip install torchvision\n",
    "#import torch\n",
    "#print(torch.__path__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ab1332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adalam import AdalamFilter\n",
    "\n",
    "class adalam_filter():\n",
    "    def __init__(self):\n",
    "        self.matcher = AdalamFilter()\n",
    "\n",
    "    def get_data(self, kps):\n",
    "        pts = np.array([k.pt for k in kps], dtype=np.float32)\n",
    "        ors = np.array([k.angle for k in kps], dtype=np.float32)\n",
    "        scs = np.array([k.size for k in kps], dtype=np.float32)\n",
    "        \n",
    "        return pts, ors, scs\n",
    "    \n",
    "    def process(self, im1, im2, kp1, kp2, dsc1, dsc2, num=-1):\n",
    "        pts1, ors1, scs1 = self.get_data(kp1)\n",
    "        pts2, ors2, scs2 = self.get_data(kp2)\n",
    "        \n",
    "        matches = self.matcher.match_and_filter(k1=pts1, k2=pts2,\n",
    "                                                o1=ors1, o2=ors2,\n",
    "                                                d1=dsc1, d2=dsc2,\n",
    "                                                s1=scs1, s2=scs2,\n",
    "                                                im1shape=im1.shape[:2], im2shape=im1.shape[:2]).cpu().numpy()\n",
    "        \n",
    "        match_indices = np.zeros(len(matches), dtype=int)\n",
    "        for i, j in enumerate(matches):\n",
    "            match_indices[i] = j[1]\n",
    "\n",
    "        \n",
    "        fig = plot_figures({'adalam matches': draw_cv_matches(im1, im2, \n",
    "                                                              np.array(kp1)[matches[:, 0]], kp2,\n",
    "                                                              match_indices)}) \n",
    "        \n",
    "        return fig,matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdbe165",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "155338b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGroundTruth(filename):\n",
    "    res = {}\n",
    "    lines = []\n",
    "    with open(filename, 'r',encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    count = 0\n",
    "    times = []\n",
    "    t = []\n",
    "    q = []\n",
    "    for line in lines[3:]:\n",
    "        #print(f'line {count}: {line}')\n",
    "        timestamp, tx, ty, tz, qx, qy, qz, qw = line.strip().split()\n",
    "        #times.append(timestamp)\n",
    "        end_of_name=timestamp.index('.')+3\n",
    "        timestamp=timestamp[:end_of_name]\n",
    "        t=np.array([float(tx), float(ty), float(tz)])\n",
    "        q=np.array([float(qx), float(qy), float(qz), float(qw)])\n",
    "        #count += 1\n",
    "        res[timestamp] = [np.array(t), np.array(q)]\n",
    "    return res\n",
    "\n",
    "def getImages(path = os.getcwd()):\n",
    "    images = []\n",
    "    for p, subdirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if \".png\" in name:\n",
    "                images.append(name)\n",
    "    return images\n",
    "\n",
    "def getDs(fileName):\n",
    "    images = getImages(fileName)\n",
    "    DsCorres = pd.read_excel (fileName+\"/DS.xls\")\n",
    "    return images, DsCorres\n",
    "\n",
    "def buildDs(imagesList, numPairs, step):\n",
    "    N = len(imagesList)\n",
    "    assert step < N - N/2#(N/2 + step) > N\n",
    "    \n",
    "    i =  np.arange(0, int(N/2), 1)\n",
    "    imagesIndexes = list(zip(i, i+step))\n",
    "    imagesNames = []\n",
    "    for first,second in imagesIndexes:\n",
    "        imagesNames.append([imagesList[first], imagesList[second]])\n",
    "    \n",
    "    return imagesNames#[[\"A\",\"B\"],[\"C\",\"dddd\"]]\n",
    "\n",
    "def getDs1(imagesList, fileName, generate = True, numPairs  = 10, step = 3):    \n",
    "    global DsCorres, wantedToTake\n",
    "    if generate:\n",
    "        selImages = buildDs(imagesList, numPairs, step)\n",
    "        \n",
    "        with open(fileName+'/DS.txt', 'w',encoding='utf-8') as f:\n",
    "            for n1, n2 in selImages:\n",
    "                f.writelines(n1 + \" \" + n2+\"\\n\")\n",
    "        \n",
    "    DsCorres =[]\n",
    "    with open(fileName+'/DS.txt', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            name1, name2 = line.strip().split()\n",
    "            DsCorres.append([name1, name2])\n",
    "\n",
    "    w = random.sample(range(len(DsCorres)), numPairs)\n",
    "    wantedToTake = []\n",
    "    for i in w:\n",
    "        wantedToTake.append(DsCorres[i])\n",
    "    #print(w)\n",
    "\n",
    "    #return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "715c4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_estimation(pts_left, pts_right):\n",
    "    '''\n",
    "    pts_left: list of cv2.KeyPoint\n",
    "    pts_right: list of cv2.KeyPoint\n",
    "    '''\n",
    "    fx = 525.0  # focal length x\n",
    "    fy = 525.0  # focal length y\n",
    "    cx = 319.5  # optical center x\n",
    "    cy = 239.5  # optical center y\n",
    "    intrinsic_mat = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "    pts1 = np.array([x.pt for x in pts_left])\n",
    "    pts2 = np.array([x.pt for x in pts_right])\n",
    "    #print(pts_left, pts_right, intrinsic_mat)\n",
    "    M, mask = cv.findEssentialMat(pts1, pts2, intrinsic_mat)\n",
    "    retval, R, t, mask = cv.recoverPose(M, pts1, pts2, intrinsic_mat)\n",
    "    \n",
    "    return t,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c25b77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(DsCorres, n2show = -1, filename = \"/Dataset\",directory2save = \"/resu\"):\n",
    "    k=0\n",
    "    p = os.getcwd()+filename\n",
    "    p2save = os.getcwd() + directory2save\n",
    "    if os.path.isdir(p2save):\n",
    "        shutil.rmtree(p2save)\n",
    "    os.mkdir(p2save)\n",
    "    \n",
    "    adalamOBJ=adalam_filter()       \n",
    "    p_bar = trange(len(DsCorres))\n",
    "    \n",
    "#     for name1, name2, x in DsCorres, p_bar:\n",
    "    lr_tran_sift=np.zeros((3,1))\n",
    "    lr_rot_sift=np.zeros((1,3,3))\n",
    "    lr_tran_orb=np.zeros((3,1))\n",
    "    lr_rot_orb=np.zeros((1,3,3))\n",
    "    adalam_tran_sift=np.zeros((3,1))\n",
    "    adalam_rot_sift=np.zeros((1,3,3))\n",
    "    adalam_tran_orb=np.zeros((3,1))\n",
    "    adalam_rot_orb=np.zeros((1,3,3))\n",
    "    \n",
    "    for i,(names, _x) in enumerate(zip(DsCorres, p_bar)):\n",
    "        name1, name2 = names\n",
    "        image1 = bgr2rgb(cv.imread(p+\"/\"+ name1))\n",
    "        image2 = bgr2rgb(cv.imread(p+\"/\"+ name2))\n",
    "        kp1, kp1_desc, imgRes1 = keyPoints(image1.copy(), type=\"SIFT\")\n",
    "        kp2, kp2_desc, imgRes2 = keyPoints(image2.copy(), type=\"SIFT\")\n",
    "        kp3, kp3_desc, imgRes3 = keyPoints(image1.copy(), type=\"ORB\")\n",
    "        kp4, kp4_desc, imgRes4 = keyPoints(image2.copy(), type=\"ORB\")\n",
    "\n",
    "#         print(\"SIFT Descriptors\")\n",
    "#         print(\"\\tShape of kp1_desc: \", kp1_desc.shape)\n",
    "#         print(\"\\tShape of kp2_desc: \", kp2_desc.shape)\n",
    "#         print(\"ORB Descriptors\")\n",
    "#         print(\"\\tShape of kp3_desc: \", kp3_desc.shape)\n",
    "#         print(\"\\tShape of kp4_desc: \", kp4_desc.shape)\n",
    "\n",
    "#         orginalImgs = plot_figures({'image1': image1, 'image2': image2}, 1, 2);        \n",
    "\n",
    "#         ResNnmatching = nnMatching(image1.copy(), image2.copy(), kp1, kp2, kp1_desc, kp2_desc, num = n2show);\n",
    "#         ResNnmatching.savefig(p2save + \"\\\\\" +\"Res_Nnmatching \" + str(k))\n",
    "#         plt.close(ResLowRatio)\n",
    "        \n",
    "#         ResLowRatio = lowRatio(image1.copy(), image2.copy(), kp1, kp1_desc, kp2, kp2_desc, r  = 1, num = n2show)\n",
    "#         ResLowRatio.savefig(p2save + \"\\\\\" +\"Res_LowRatio_SIFT \" + str(k))\n",
    "#         plt.close(ResLowRatio)\n",
    "        \n",
    "#         ResLowRatio = lowRatio(image1.copy(), image2.copy(), kp3, kp3_desc, kp4, kp4_desc, r  = 1, num = n2show)\n",
    "#         ResLowRatio.savefig(p2save + \"\\\\\" +\"Res_LowRatio_ORB \" + str(k))\n",
    "#         plt.close(ResLowRatio)\n",
    " \n",
    "        ResLowRatio,lr_matches_sift = mutual_lowRatio(image1.copy(), image2.copy(), kp1, kp1_desc, kp2, kp2_desc, r  = 0.95, num = n2show)\n",
    "        lowratio_time = %timeit -o mutual_lowRatio(image1.copy(), image2.copy(), kp1, kp1_desc, kp2, kp2_desc, r  = 0.95, num = n2show)\n",
    "        print(f'Iter {i} Lowe ration time consumption: {lowratio_time}')\n",
    "        ResLowRatio.savefig(p2save + \"/\" +\"Res_mutual_LowRatio_SIFT \" + str(k))\n",
    "        plt.close(ResLowRatio)\n",
    "        t,r=pos_estimation(kp1[lr_matches_sift[:,0]],kp2[lr_matches_sift[:,1]])\n",
    "        lr_tran_sift=np.concatenate((lr_tran_sift,t),axis=1)\n",
    "        lr_rot_sift=np.concatenate((lr_rot_sift,r[None, :, :]),axis=0)\n",
    "        \n",
    "        ResLowRatio,lr_matches_orb = mutual_lowRatio(image1.copy(), image2.copy(), kp3, kp3_desc, kp4, kp4_desc, r  = 0.95, num = n2show)\n",
    "        ResLowRatio.savefig(p2save + \"/\" +\"Res_mutual_LowRatio_ORB \" + str(k))\n",
    "        plt.close(ResLowRatio)\n",
    "        t,r=pos_estimation(kp1[lr_matches_orb[:,0]],kp2[lr_matches_orb[:,1]])\n",
    "        lr_tran_orb=np.concatenate((lr_tran_orb,t),axis=1)\n",
    "        lr_rot_orb=np.concatenate((lr_rot_orb,r[None, :, :]),axis=0)\n",
    "        \n",
    "        ResAdalam,adalam_matches_sift=adalamOBJ.process(image1.copy(), image2.copy(), kp1, kp2, kp1_desc, kp2_desc,num = n2show)\n",
    "        adalam_time = %timeit -o adalamOBJ.process(image1.copy(), image2.copy(), kp1, kp2, kp1_desc, kp2_desc,num = n2show)\n",
    "        print(f'Iter {i} Lowe ration time consumption: {adalam_time}')\n",
    "        ResAdalam.savefig(p2save + \"/\" +\"Res_Adalam_SIFT \" + str(k))\n",
    "        plt.close(ResAdalam)\n",
    "        t,r=pos_estimation(kp1[adalam_matches_sift[:,0]],kp2[adalam_matches_sift[:,1]])\n",
    "        adalam_tran_sift=np.concatenate((adalam_tran_sift,t),axis=1)\n",
    "        adalam_rot_sift=np.concatenate((adalam_rot_sift,r[None, :, :]),axis=0)\n",
    "        \n",
    "        ResAdalam,adalam_matches_orb=adalamOBJ.process(image1.copy(), image2.copy(), kp3, kp4, kp3_desc, kp4_desc,num = n2show)\n",
    "        ResAdalam.savefig(p2save + \"/\" +\"Res_Adalam_ORB \" + str(k))\n",
    "        plt.close(ResAdalam)\n",
    "        t,r=pos_estimation(kp1[adalam_matches_orb[:,0]],kp2[adalam_matches_orb[:,1]])\n",
    "        adalam_tran_orb=np.concatenate((adalam_tran_orb,t),axis=1)\n",
    "        adalam_rot_orb=np.concatenate((adalam_rot_orb,r[None, :, :]),axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         ResBFMatching = BFMatching(image1.copy(), image2.copy(), kp3, kp4, kp3_desc, kp4_desc, num = n2show);\n",
    "#         ResBFMatSiftLowR = BFMatSiftLowR(image1.copy(), image2.copy(),k = 2, r = 0.75, num = n2show)\n",
    "#         plt.close(ResBFMatSiftLowR)\n",
    "        \n",
    "        k += 1\n",
    "    return {'lr_sift': {'tran': lr_tran_sift[:,1:],\n",
    "                        'rot': lr_rot_sift[1:]},\n",
    "            'lr_orb': {'tran': lr_tran_orb[:,1:],\n",
    "                        'rot': lr_rot_orb[1:]},\n",
    "            'adalam_sift': {'tran': adalam_tran_sift[:, 1:],\n",
    "                            'rot': adalam_rot_sift[1:]},\n",
    "            'adalam_orb': {'tran': adalam_tran_orb[:, 1:],\n",
    "                            'rot': adalam_rot_orb[1:]}}\n",
    "        #p_bar.set_description(f'{k} pairs is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff70fdb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbeae7cdb8f44a69b073cbe5c122f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global DsCorres, numPairs, wantedToTake, tran_rot_estimation\n",
    "\n",
    "dataSetPath = os.getcwd()+\"/Dataset\"\n",
    "imagesList = getImages(dataSetPath)\n",
    "limit = int(len(imagesList) - len(imagesList)/2)\n",
    "# print(limit)\n",
    "step = 7\n",
    "numPairs = 17\n",
    "getDs1(imagesList, dataSetPath, True, numPairs, step)\n",
    "print(len(wantedToTake))\n",
    "# interact(getDs1, imagesList = fixed(imagesList), fileName = fixed(dataSetPath), generate = fixed(True),\n",
    "#          numPairs = widgets.IntSlider(min=1, max = int(len(imagesList)/2), step=1, value = int(len(imagesList)/2)),\n",
    "#                      step = widgets.IntSlider(min=1, max=limit, step=1, value=limit));\n",
    "\n",
    "# testBtn =widgets.Button(\n",
    "#     value=False,\n",
    "#     description='Start Testing',\n",
    "#     disabled=False,\n",
    "#     button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "#     tooltip='Run experiments',\n",
    "#     icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    "# )\n",
    "\n",
    "# out = widgets.Output()\n",
    "# # tran_rot_estimation = None\n",
    "# def on_button_clicked(_):\n",
    "#     with out:\n",
    "#         #clear_output()\n",
    "#         #test(DsCorres,n2show = 20, filename = \"\\Dataset\", directory2save = \"\\\\ggg\")\n",
    "#         tran_rot_estimation = test(wantedToTake,n2show = 20, filename = \"/Dataset\", directory2save = \"/ggg\")\n",
    "#     return tran_rot_estimation\n",
    "# testBtn.on_click(on_button_clicked)\n",
    "# widgets.VBox([testBtn,out])\n",
    "tran_rot_estimation = test(wantedToTake,n2show = 20, filename = \"/Dataset\", directory2save = \"/ggg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2137deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "GroundTruth= readGroundTruth(os.getcwd()+\"/Dataset/groundtruth.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73775dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ffb6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set_pairs(DsCorres):\n",
    "    data_set_pairs=np.array(DsCorres)\n",
    "    for pair in data_set_pairs:\n",
    "        end_of_name=pair[0].index('.')+3\n",
    "        pair[0]=pair[0][:end_of_name]\n",
    "        end_of_name=pair[1].index('.')+3\n",
    "        pair[1]=pair[1][:end_of_name]\n",
    "    return data_set_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21aefaec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 3)\n",
      "(17, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Compare the data_set_pairs and the groundTruth\n",
    "from scipy.spatial.transform import Rotation as rotation\n",
    "\n",
    "def pos_rot_error_GT(data_set_pairs,GroundTruth):\n",
    "    rot_first2second_all=np.zeros((1,3,3))\n",
    "    pos_first2second_all=np.zeros((1,3))\n",
    "    rot_ground2first_all=np.zeros((1,3,3))\n",
    "    pos_ground2first_all=np.zeros((1,3))\n",
    "    \n",
    "    for i in range(len(data_set_pairs)):\n",
    "        pos_quat_first=GroundTruth[data_set_pairs[i][0]]\n",
    "        pos_quat_second=GroundTruth[data_set_pairs[i][1]]\n",
    "        pos_first=pos_quat_first[0]\n",
    "        pos_second=pos_quat_second[0]\n",
    "        quat_first=pos_quat_first[1]\n",
    "        quat_second=pos_quat_second[1]\n",
    "        \n",
    "        pos_first2second=pos_second-pos_first\n",
    "#         print(pos_first2second/np.linalg.norm(pos_first2second))\n",
    "#         pos_error=np.linalg.norm(pos_first2second)\n",
    "        quat_first= rotation.from_quat(quat_first)\n",
    "        quat_second= rotation.from_quat(quat_second)\n",
    "        rot_first= quat_first.as_matrix()\n",
    "        rot_second=quat_second.as_matrix()\n",
    "        rot_first2second=(rot_second)@(rot_first.T)\n",
    "#         rot_first2second=(rot_first.T)@(rot_second)\n",
    "#         theta_error=rotation.as_rotvec(rotation_error)\n",
    "        pos_first2second_all=np.vstack((pos_first2second_all,pos_first2second[None]))\n",
    "        rot_first2second_all=np.vstack((rot_first2second_all,rot_first2second[None]))\n",
    "        rot_ground2first_all=np.vstack((rot_ground2first_all,rot_first[None]))\n",
    "        pos_ground2first_all=np.vstack((pos_ground2first_all,pos_first[None]))\n",
    "        \n",
    "    return pos_first2second_all[1:],rot_first2second_all[1:],rot_ground2first_all[1:],pos_ground2first_all[1:]\n",
    "\n",
    "data_set_pairs=get_data_set_pairs(DsCorres)\n",
    "pos_diff_GT,rot_diff_GT,rot_ground2first,pos_ground2first=pos_rot_error_GT(data_set_pairs,GroundTruth)\n",
    "print(pos_diff_GT.shape)\n",
    "print(rot_diff_GT.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a16889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99958006, -0.0010793 ,  0.02895747],\n",
       "       [ 0.00175902,  0.99972327, -0.02345811],\n",
       "       [-0.02892414,  0.0234992 ,  0.99930535]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_diff_GT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38013811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99984002, -0.01135548, -0.01381955],\n",
       "       [ 0.01153516,  0.99984905,  0.01299265],\n",
       "       [ 0.01366992, -0.01314999,  0.99982009]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_rot_estimation['lr_sift']['rot'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84533815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9993432 , -0.01743586, -0.03176717],\n",
       "       [ 0.01773628,  0.99980037,  0.00919989],\n",
       "       [ 0.03160042, -0.00975728,  0.99945295]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_rot_estimation['adalam_sift']['rot'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6295d1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03808487, 0.27167512, 0.96163516])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_rot_estimation['adalam_sift']['tran'][:,0]# we don't need it, useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbaf6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing scores for method lr_sift\n",
      "Computing scores for method lr_orb\n",
      "Computing scores for method adalam_sift\n",
      "Computing scores for method adalam_orb\n"
     ]
    }
   ],
   "source": [
    "# Calculate the error in pos and rotion between ground truth and real estimation\n",
    "def pos_rot_error(pos_diff_GT,rot_diff_GT,pos_diff_estimation,rot_diff_estimation,rot_ground2first,pos_ground2first):\n",
    "    theta_error_all=np.zeros(1)\n",
    "    pos_error_all=np.zeros(1)\n",
    "    for pos_GT,pos_estimation,rot_GT,rot_estimation,rot_g2f,pos_g2f in zip(pos_diff_GT,pos_diff_estimation,rot_diff_GT,rot_diff_estimation,rot_ground2first,pos_ground2first):\n",
    "#         print(pos_estimation.shape)\n",
    "#         pos_error=np.linalg.norm(pos_GT-pos_estimation)\n",
    "\n",
    "        rot_modify=np.concatenate((rot_g2f,[[0,0,0]]),axis=0)\n",
    "        tran_modify=np.concatenate((pos_g2f,np.array([1])),axis=0).reshape((4,1))\n",
    "        transform_mat=np.concatenate((rot_modify,tran_modify),axis=1)\n",
    "        pos_estimation_modify=np.concatenate((pos_estimation,np.array([1])),axis=0)\n",
    "        pos_estimation_ground=np.linalg.inv(transform_mat)@pos_estimation_modify\n",
    "        pos_estimation_ground=pos_estimation_ground[:-1]\n",
    "#         print(pos_estimation_ground)\n",
    "        pos_error=np.arccos(np.dot(pos_GT,pos_estimation_ground)/(np.linalg.norm(pos_GT)*np.linalg.norm(pos_estimation_ground)))\n",
    "#         print(pos_error)\n",
    "        rot_error=rot_GT@(rot_estimation.T)\n",
    "        rot_error=rotation.from_matrix(rot_error)\n",
    "        theta_error=np.linalg.norm(rot_error.as_rotvec())\n",
    "        theta_error_all=np.concatenate((theta_error_all,np.array([theta_error])))\n",
    "        pos_error_all=np.concatenate((pos_error_all,np.array([pos_error])))\n",
    "    \n",
    "    return pos_error_all[1:],theta_error_all[1:]\n",
    "\n",
    "# Rotation and translation estimation\n",
    "\n",
    "# Kinect intrinsics\n",
    "errors = dict()\n",
    "for k in tran_rot_estimation.keys():\n",
    "    print(f'Computing scores for method {k}')\n",
    "    estim = tran_rot_estimation[k]\n",
    "    errors[k] = dict()\n",
    "#     print(estim['tran'].shape)\n",
    "    pos_error_all,rot_error_all=pos_rot_error(pos_diff_GT,rot_diff_GT,estim['tran'].T, estim['rot'],rot_ground2first,pos_ground2first)\n",
    "    errors[k]['pos_error'] = pos_error_all\n",
    "    errors[k]['rot_error'] = rot_error_all\n",
    "    \n",
    "# pos_diff_estimation,rot_diff_estimation=pos_estimation(pts_left,pts_right)\n",
    "# pos_error_all,rot_error_all=pos_rot_error(pos_diff_GT,rot_diff_GT,pos_diff_estimation,rot_diff_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d8c6e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.89472786, 2.70688751, 1.98119283, 3.38187513, 3.37999497,\n",
       "       3.15071852, 2.09784958, 3.05978461, 3.78373089, 5.53596457,\n",
       "       4.42266603, 4.14968708, 6.48630862, 4.88149154, 2.25338555,\n",
       "       5.55839633, 4.23220279])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rad2deg(errors['adalam_sift']['rot_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81856ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.89557965, 3.28825455, 1.9453104 , 3.46456174, 2.20295288,\n",
       "       3.3447008 , 1.42594655, 3.19738647, 3.99711002, 5.26970237,\n",
       "       4.77739348, 4.30363107, 5.90667044, 4.07403124, 2.1938658 ,\n",
       "       5.62379163, 3.59132427])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rad2deg(errors['lr_sift']['rot_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d192daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56.4145306 , 105.98151186, 120.48043351, 120.18353038,\n",
       "       123.45660817, 110.22457922,  55.92130757,  60.44650252,\n",
       "        58.01836185,  65.2840719 ,  64.29506356,  56.10399598,\n",
       "       118.44270298,  62.99052897, 105.58661902, 115.66543874,\n",
       "        67.63166784])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rad2deg(errors['adalam_sift']['pos_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d309d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56.31289116, 126.01007824, 121.3848524 , 119.89904528,\n",
       "       124.16913019, 110.10458208,  56.48053956,  60.17062106,\n",
       "        58.75039922,  64.96457813,  63.43299123,  55.03985649,\n",
       "       119.25079212,  61.0481572 , 111.22849577, 115.73483771,\n",
       "        59.16233839])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rad2deg(errors['lr_sift']['pos_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829acf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
